{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T19:56:14.634659Z",
     "start_time": "2018-03-09T19:56:14.625799Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T17:05:12.015599Z",
     "start_time": "2018-03-09T17:05:12.006730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Normal_7/log_prob/sub:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normal(1.0,0.0).log_prob(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "55000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.2356 - acc: 0.9319\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0909 - acc: 0.9723\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0571 - acc: 0.9823\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0369 - acc: 0.9890\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0263 - acc: 0.9925\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0186 - acc: 0.9945\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0133 - acc: 0.9965\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0135 - acc: 0.9958\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0069 - acc: 0.9977\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0101 - acc: 0.9967\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0045 - acc: 0.9987\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 7.2738e-04 - acc: 0.9999\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0096 - acc: 0.9967\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0030 - acc: 0.9989\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0037 - acc: 0.9988\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0065 - acc: 0.9977\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0039 - acc: 0.9986\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.1191e-04 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 4.0936e-05 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.7885e-05 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.2226e-05 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.8102e-05 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.4891e-05 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.2298e-05 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.0184e-05 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 8.4133e-06 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 6.8513e-06 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 5.9973e-06 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 4.6896e-06 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 3.7978e-06 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 3.0692e-06 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.5508e-06 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.0785e-06 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.7169e-06 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3723e-06 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.1297e-06 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 9.5606e-07 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 7.8074e-07 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 6.4752e-07 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0217 - acc: 0.9954\n",
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.0064 - acc: 0.9980\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 8.3614e-04 - acc: 0.9998\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 7.7901e-05 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.6368e-05 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.8998e-05 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.5336e-05 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.2558e-05 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.0477e-05 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 8.6892e-06 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 7.2259e-06 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 5.9625e-06 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 4.9081e-06 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 4.0665e-06 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 3.3114e-06 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.7919e-06 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.2757e-06 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.8530e-06 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.5222e-06 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3280e-06 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.1265e-06 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 8.7117e-07 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 7.1225e-07 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 5.9591e-07 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 5.0589e-07 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 4.3200e-07 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 3.7822e-07 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 3.2740e-07 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.8819e-07 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.6328e-07 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.3595e-07 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 2.1245e-07 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.9804e-07 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.8472e-07 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.7319e-07 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.6416e-07 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.5718e-07 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.5112e-07 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.4672e-07 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.4243e-07 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3914e-07 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3659e-07 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3445e-07 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3226e-07 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.3086e-07 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.2942e-07 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 1.2825e-07 - acc: 1.0000\n",
      "Test loss: 0.1040928958138272\n",
      "Test accuracy: 0.9853\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu', input_shape=(784,)))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "                    #validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T20:00:07.160507Z",
     "start_time": "2018-03-09T20:00:03.088808Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.random.randn(10000, 10)\n",
    "y = X@np.random.randn(10,1)+np.random.randn(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T20:07:47.677879Z",
     "start_time": "2018-03-09T20:07:43.355859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 3.0804 - mean_squared_error: 37.1339\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.6434 - mean_squared_error: 24.3681\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.5240 - mean_squared_error: 9.3762\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4638 - mean_squared_error: 11.2753\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4652 - mean_squared_error: 12.2161\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4548 - mean_squared_error: 10.6556\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4510 - mean_squared_error: 10.8928\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4461 - mean_squared_error: 11.1738\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4440 - mean_squared_error: 10.7496\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4428 - mean_squared_error: 10.9861\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4402 - mean_squared_error: 10.9126\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4383 - mean_squared_error: 10.7852\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4371 - mean_squared_error: 10.9900\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4358 - mean_squared_error: 10.6109\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4329 - mean_squared_error: 10.9529\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4313 - mean_squared_error: 10.6328\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4286 - mean_squared_error: 10.8275\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4275 - mean_squared_error: 10.7398\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4258 - mean_squared_error: 10.7403\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4223 - mean_squared_error: 10.6149\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4211 - mean_squared_error: 10.7170\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4190 - mean_squared_error: 10.6390\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 2.4178 - mean_squared_error: 10.6137\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4159 - mean_squared_error: 10.6491\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4151 - mean_squared_error: 10.5868\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4130 - mean_squared_error: 10.5367\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4115 - mean_squared_error: 10.7360\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4094 - mean_squared_error: 10.4815\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4083 - mean_squared_error: 10.6001\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4065 - mean_squared_error: 10.5149\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4052 - mean_squared_error: 10.5720\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4039 - mean_squared_error: 10.4780\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4032 - mean_squared_error: 10.5423\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4015 - mean_squared_error: 10.4240\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.4004 - mean_squared_error: 10.5797\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3998 - mean_squared_error: 10.4375\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3991 - mean_squared_error: 10.4260\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3982 - mean_squared_error: 10.5456\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3973 - mean_squared_error: 10.4616\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3966 - mean_squared_error: 10.4089\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3961 - mean_squared_error: 10.4826\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3950 - mean_squared_error: 10.5002\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3945 - mean_squared_error: 10.3685\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3941 - mean_squared_error: 10.4253\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3937 - mean_squared_error: 10.4582\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3926 - mean_squared_error: 10.5106\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3922 - mean_squared_error: 10.2941\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3927 - mean_squared_error: 10.4653\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3915 - mean_squared_error: 10.4648\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3916 - mean_squared_error: 10.3953\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3916 - mean_squared_error: 10.3499\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3921 - mean_squared_error: 10.3922\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3911 - mean_squared_error: 10.5368\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3914 - mean_squared_error: 10.4470\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3907 - mean_squared_error: 10.3517\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3900 - mean_squared_error: 10.3945\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3898 - mean_squared_error: 10.4296\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3895 - mean_squared_error: 10.3998\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3889 - mean_squared_error: 10.3464\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3899 - mean_squared_error: 10.3852\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3892 - mean_squared_error: 10.5076\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3891 - mean_squared_error: 10.3667\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3892 - mean_squared_error: 10.3596\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3892 - mean_squared_error: 10.3852\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3887 - mean_squared_error: 10.4694\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3894 - mean_squared_error: 10.4652\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3896 - mean_squared_error: 10.4100\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3892 - mean_squared_error: 10.3421\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3878 - mean_squared_error: 10.3896\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3877 - mean_squared_error: 10.3792\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3880 - mean_squared_error: 10.3674\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3876 - mean_squared_error: 10.4280\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3871 - mean_squared_error: 10.3854\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3873 - mean_squared_error: 10.3387\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3873 - mean_squared_error: 10.3911\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3880 - mean_squared_error: 10.4210\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3879 - mean_squared_error: 10.2970\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3879 - mean_squared_error: 10.4514\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3875 - mean_squared_error: 10.4150\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3875 - mean_squared_error: 10.4273\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3872 - mean_squared_error: 10.3963\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3874 - mean_squared_error: 10.3626\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3872 - mean_squared_error: 10.2964\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3870 - mean_squared_error: 10.4564\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3866 - mean_squared_error: 10.4110\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3867 - mean_squared_error: 10.2481\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3878 - mean_squared_error: 10.4862\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3864 - mean_squared_error: 10.4156\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3860 - mean_squared_error: 10.3641\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3858 - mean_squared_error: 10.2941\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3859 - mean_squared_error: 10.4662\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3865 - mean_squared_error: 10.3910\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3864 - mean_squared_error: 10.3376\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3862 - mean_squared_error: 10.3361\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3871 - mean_squared_error: 10.3642\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3859 - mean_squared_error: 10.4398\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3856 - mean_squared_error: 10.3511\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3857 - mean_squared_error: 10.3052\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3856 - mean_squared_error: 10.4652\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 2.3857 - mean_squared_error: 10.3652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ef329fd68>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = Input(shape=(10,), name='aux_input')\n",
    "x = Dense(512, activation='relu')(input_)\n",
    "x = Lambda(lambda x: K.dropout(x, level=0.5))(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Lambda(lambda x: K.dropout(x, level=0.5))(x)\n",
    "mean = Dense(1, activation='linear')(x)\n",
    "std = Dense(1, activation=lambda y: K.exp(y))(x)\n",
    "out = keras.layers.concatenate([mean, std])\n",
    "\n",
    "model = Model(inputs=[input_], outputs=[out])\n",
    "\n",
    "def customLoss(yTrue,yPred):\n",
    "    mean = yPred[:,0]\n",
    "    std = yPred[:,1]\n",
    "    return -K.mean(Normal(mean, std).log_prob(yTrue))\n",
    "\n",
    "model.compile(loss=customLoss,\n",
    "      optimizer=Adam(),\n",
    "      metrics=['mse'])\n",
    "\n",
    "model.fit(X, y,\n",
    "            batch_size=1000,\n",
    "            epochs=100,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T20:03:25.423552Z",
     "start_time": "2018-03-09T20:03:25.180868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0144145 , 1.0102267 , 1.0158489 , ..., 0.98650604, 0.9928834 ,\n",
       "       1.0277765 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T20:07:29.495135Z",
     "start_time": "2018-03-09T20:07:25.693403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 2.2445 - mean_squared_error: 6.3885\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 1.6899 - mean_squared_error: 4.3578\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 1.5838 - mean_squared_error: 4.1130\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 1.5417 - mean_squared_error: 4.0593\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 1.5348 - mean_squared_error: 4.0458\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.5035 - mean_squared_error: 4.0075\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.5050 - mean_squared_error: 4.0064\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4920 - mean_squared_error: 3.9894\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4846 - mean_squared_error: 3.9804\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4857 - mean_squared_error: 3.9816\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4725 - mean_squared_error: 3.9696\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4716 - mean_squared_error: 3.9680\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4694 - mean_squared_error: 3.9659\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4698 - mean_squared_error: 3.9659\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4580 - mean_squared_error: 3.9520\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4673 - mean_squared_error: 3.9604\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4667 - mean_squared_error: 3.9575\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4566 - mean_squared_error: 3.9463\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4617 - mean_squared_error: 3.9519\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4603 - mean_squared_error: 3.9500\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4520 - mean_squared_error: 3.9406\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4537 - mean_squared_error: 3.9444\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4531 - mean_squared_error: 3.9440\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4491 - mean_squared_error: 3.9396\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4503 - mean_squared_error: 3.9407\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4467 - mean_squared_error: 3.9377\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4470 - mean_squared_error: 3.9385\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4445 - mean_squared_error: 3.9367\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4460 - mean_squared_error: 3.9364\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4473 - mean_squared_error: 3.9377\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4391 - mean_squared_error: 3.9295\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4406 - mean_squared_error: 3.9307\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4497 - mean_squared_error: 3.9405\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4407 - mean_squared_error: 3.9309\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4413 - mean_squared_error: 3.9315\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4362 - mean_squared_error: 3.9265\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4359 - mean_squared_error: 3.9264\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4335 - mean_squared_error: 3.9236\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4349 - mean_squared_error: 3.9244\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4346 - mean_squared_error: 3.9240\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4358 - mean_squared_error: 3.9255\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4282 - mean_squared_error: 3.9179\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4363 - mean_squared_error: 3.9265\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4371 - mean_squared_error: 3.9272\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4317 - mean_squared_error: 3.9219\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4328 - mean_squared_error: 3.9227\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4296 - mean_squared_error: 3.9193\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4319 - mean_squared_error: 3.9211\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4285 - mean_squared_error: 3.9177\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4269 - mean_squared_error: 3.9151\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4318 - mean_squared_error: 3.9204\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4299 - mean_squared_error: 3.9182\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4257 - mean_squared_error: 3.9141\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4313 - mean_squared_error: 3.9194\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4298 - mean_squared_error: 3.9184\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4267 - mean_squared_error: 3.9151\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4198 - mean_squared_error: 3.9080\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4212 - mean_squared_error: 3.9096\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4325 - mean_squared_error: 3.9209\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4325 - mean_squared_error: 3.9210\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4236 - mean_squared_error: 3.9118\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4270 - mean_squared_error: 3.9150\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4275 - mean_squared_error: 3.9151\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4231 - mean_squared_error: 3.9108\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4222 - mean_squared_error: 3.9101\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4195 - mean_squared_error: 3.9072\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4248 - mean_squared_error: 3.9129\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4279 - mean_squared_error: 3.9164\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4259 - mean_squared_error: 3.9148\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4283 - mean_squared_error: 3.9165\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4222 - mean_squared_error: 3.9099\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4253 - mean_squared_error: 3.9129\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4117 - mean_squared_error: 3.9001\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4188 - mean_squared_error: 3.9074\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4262 - mean_squared_error: 3.9149\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4226 - mean_squared_error: 3.9109\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4248 - mean_squared_error: 3.9129\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4151 - mean_squared_error: 3.9025\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4205 - mean_squared_error: 3.9081\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4170 - mean_squared_error: 3.9046\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4252 - mean_squared_error: 3.9133\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4166 - mean_squared_error: 3.9044\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4148 - mean_squared_error: 3.9028\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4232 - mean_squared_error: 3.9115\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4139 - mean_squared_error: 3.9022\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4171 - mean_squared_error: 3.9060\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4122 - mean_squared_error: 3.9004\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4199 - mean_squared_error: 3.9081\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4164 - mean_squared_error: 3.9039\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4163 - mean_squared_error: 3.9041\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4127 - mean_squared_error: 3.8999\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4161 - mean_squared_error: 3.9042\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4149 - mean_squared_error: 3.9027\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4155 - mean_squared_error: 3.9031\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4134 - mean_squared_error: 3.9009\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4158 - mean_squared_error: 3.9039\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4089 - mean_squared_error: 3.8975\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4133 - mean_squared_error: 3.9016\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4206 - mean_squared_error: 3.9095\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 3us/step - loss: 1.4216 - mean_squared_error: 3.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ef5306f60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = Input(shape=(10,), name='aux_input')\n",
    "x = Dense(512, activation='relu')(input_)\n",
    "x = Lambda(lambda x: K.dropout(x, level=0.5))(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Lambda(lambda x: K.dropout(x, level=0.5))(x)\n",
    "mean = Dense(1, activation='linear')(x)\n",
    "std = Dense(1, activation=lambda y: K.exp(y))(x)\n",
    "out = keras.layers.concatenate([mean, std])\n",
    "\n",
    "model = Model(inputs=[input_], outputs=[out])\n",
    "\n",
    "def log_gaussian2(x, mean, log_std):\n",
    "    log_var = 2*log_std\n",
    "    return -K.log(2*np.pi)/2.0 - log_var/2.0 - (x-mean)**2/(2*K.exp(log_var))\n",
    "\n",
    "def customLoss(y_true, y_pred):\n",
    "    return -log_gaussian2(y_pred[:, 0], y_true[:, 0], y_pred[:, 1])\n",
    "\n",
    "model.compile(loss=customLoss,\n",
    "      optimizer=Adam(),\n",
    "      metrics=['mse'])\n",
    "\n",
    "model.fit(X, y,\n",
    "            batch_size=1000,\n",
    "            epochs=100,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T20:04:37.689486Z",
     "start_time": "2018-03-09T20:04:37.684777Z"
    }
   },
   "outputs": [],
   "source": [
    "a=Normal(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T20:04:50.337526Z",
     "start_time": "2018-03-09T20:04:50.321729Z"
    }
   },
   "outputs": [],
   "source": [
    "a.log_prob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
