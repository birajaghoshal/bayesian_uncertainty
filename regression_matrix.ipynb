{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit, KFold, RepeatedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from datasets import make_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = make_datasets(year=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from metrics import normal_nll, rmse, mae, auc_rmse, auc_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from shallow_models import LinearRegression, BayesianLinearRegression, GBTQuantile, RFUncertainty, XGBaseline, XGBLogLikelihood\n",
    "models = [RFUncertainty, LinearRegression, BayesianLinearRegression, GBTQuantile, XGBaseline, XGBLogLikelihood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = namedtuple('Results', 'datetime dataset model shape normal_nll rmse mae auc_rmse auc_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results(datetime='2018-03-01 19:57:22.695867', dataset='boston', model='RFUncertainty', shape=(506, 13), normal_nll=(2.455614031620532e+57, 2.4556140316205316e+57), rmse=(4.066076679841884e+57, 4.066076679841884e+57), mae=(5.71920948616602e+57, 5.7192094861660194e+57), auc_rmse=(2.216876086956517e+57, 2.2168760869565172e+57), auc_mae=(2.1445731225296325e+57, 2.144573122529632e+57))\n",
      "Results(datetime='2018-03-01 19:57:23.174432', dataset='boston', model='LinearRegression', shape=(506, 13), normal_nll=(3.869981139822862, 0.33501465337831454), rmse=(3.869981139822862, 0.33501465337831454), mae=(3.869981139822862, 0.33501465337831454), auc_rmse=(3.869981139822862, 0.33501465337831454), auc_mae=(3.869981139822862, 0.33501465337831454))\n",
      "Results(datetime='2018-03-01 19:57:23.638335', dataset='boston', model='BayesianLinearRegression', shape=(506, 13), normal_nll=(3.987720908492345, 0.4216856005732957), rmse=(3.987720908492345, 0.4216856005732957), mae=(3.987720908492345, 0.4216856005732957), auc_rmse=(3.987720908492345, 0.4216856005732957), auc_mae=(3.987720908492345, 0.4216856005732957))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-1dea3df39ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mpred_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             cv_metrics.append((\n",
      "\u001b[0;32m~/bayesian_uncertainty/shallow_models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgbt_lower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgbt_upper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgbt_median\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m                 \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for d, (X,y) in datasets.items():\n",
    "    try:\n",
    "        X = X.values\n",
    "        y = y.values\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    if d == 'year':\n",
    "        cv = ShuffleSplit(1, test_size=0.1)\n",
    "    elif d == 'protein':\n",
    "        cv = KFold(n_splits=3)\n",
    "    elif d.startswith('make'):\n",
    "        cv = KFold(n_splits=2)\n",
    "    else:\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=1)\n",
    "    \n",
    "    for m in models:\n",
    "        reg = m()\n",
    "        cv_metrics = []\n",
    "        for train_index, test_index in cv.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            reg.fit(X, y)\n",
    "            pred_mean, pred_std = reg.predict(X)\n",
    "            cv_metrics.append((\n",
    "                normal_nll(y, pred_mean, pred_std),\n",
    "                rmse(y, pred_mean),\n",
    "                mae(y, pred_mean),\n",
    "                auc_rmse(y, pred_mean, pred_std),\n",
    "                auc_mae(y, pred_mean, pred_std)))\n",
    "\n",
    "        metrics_mean = np.mean(cv_metrics, axis = 1)\n",
    "        metrics_stderr = scipy.stats.sem(cv_metrics, axis = 1)\n",
    "        \n",
    "        r = Results(\n",
    "                str(datetime.now()),\n",
    "                d, \n",
    "                m.__name__,\n",
    "                X.shape,\n",
    "                *zip(metrics_mean, metrics_stderr)\n",
    "            )\n",
    "        results.append(r)\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results(datetime='2018-02-28 21:24:21.068409', dataset='boston', model='LinearRegression', shape=(506, 13), normal_nll=(3.869981139822862, 0.33501465337831454), rmse=(3.869981139822862, 0.33501465337831454), mae=(3.869981139822862, 0.33501465337831454), auc_rmse=(3.869981139822862, 0.33501465337831454), auc_mae=(3.869981139822862, 0.33501465337831454))\n",
      "Results(datetime='2018-02-28 21:24:21.169216', dataset='yacht', model='LinearRegression', shape=(308, 6), normal_nll=(7.057690588006613, 0.9092927174428592), rmse=(7.057690588006613, 0.9092927174428592), mae=(7.057690588006613, 0.9092927174428592), auc_rmse=(7.057690588006613, 0.9092927174428592), auc_mae=(7.057690588006613, 0.9092927174428592))\n",
      "Results(datetime='2018-02-28 21:24:22.710413', dataset='energy', model='LinearRegression', shape=(768, 8), normal_nll=(2.7577124067912324, 0.23897518027914125), rmse=(2.7577124067912324, 0.23897518027914125), mae=(2.7577124067912324, 0.23897518027914125), auc_rmse=(2.7577124067912324, 0.23897518027914125), auc_mae=(2.7577124067912324, 0.23897518027914125))\n",
      "Results(datetime='2018-02-28 21:24:24.953951', dataset='concrete', model='LinearRegression', shape=(1030, 8), normal_nll=(9.190855325977116, 1.5341965511952675), rmse=(9.190855325977116, 1.5341965511952675), mae=(9.190855325977116, 1.5341965511952675), auc_rmse=(9.190855325977116, 1.5341965511952675), auc_mae=(9.190855325977116, 1.5341965511952675))\n",
      "Results(datetime='2018-02-28 21:24:31.427372', dataset='wine', model='LinearRegression', shape=(1599, 11), normal_nll=(0.7181499674952672, 0.08058671935900884), rmse=(0.7181499674952672, 0.08058671935900884), mae=(0.7181499674952672, 0.08058671935900884), auc_rmse=(0.7181499674952672, 0.08058671935900884), auc_mae=(0.7181499674952672, 0.08058671935900884))\n",
      "Results(datetime='2018-02-28 21:32:29.519170', dataset='kin8nm', model='LinearRegression', shape=(8192, 8), normal_nll=(0.13275711494243403, 0.0801192843490515), rmse=(0.13275711494243403, 0.0801192843490515), mae=(0.13275711494243403, 0.0801192843490515), auc_rmse=(0.13275711494243403, 0.0801192843490515), auc_mae=(0.13275711494243403, 0.0801192843490515))\n",
      "Results(datetime='2018-02-28 21:33:15.195628', dataset='power', model='LinearRegression', shape=(9568, 4), normal_nll=(4.292856783746488, 0.4629006485479337), rmse=(4.292856783746488, 0.4629006485479337), mae=(4.292856783746488, 0.4629006485479337), auc_rmse=(4.292856783746488, 0.4629006485479337), auc_mae=(4.292856783746488, 0.4629006485479337))\n",
      "Results(datetime='2018-02-28 21:39:08.511584', dataset='naval', model='LinearRegression', shape=(11934, 16), normal_nll=(-0.7403833836515382, 0.7462827679273057), rmse=(-0.7403833836515382, 0.7462827679273057), mae=(-0.7403833836515382, 0.7462827679273057), auc_rmse=(-0.7403833836515382, 0.7462827679273057), auc_mae=(-0.7403833836515382, 0.7462827679273057))\n"
     ]
    }
   ],
   "source": [
    "def eval_dataset_model(d, X, y):\n",
    "    try:\n",
    "        X = X.values\n",
    "        y = y.values\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    if d == 'year':\n",
    "        cv = ShuffleSplit(1, test_size=0.1)\n",
    "    elif d == 'protein':\n",
    "        cv = KFold(n_splits=3)\n",
    "    elif d.startswith('make'):\n",
    "        cv = KFold(n_splits=2)\n",
    "    else:\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=1)\n",
    "    \n",
    "    for m in models:\n",
    "        reg = m()\n",
    "        cv_metrics = []\n",
    "        for train_index, test_index in cv.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            reg.fit(X, y)\n",
    "            pred_mean, pred_std = reg.predict(X)\n",
    "            cv_metrics.append((\n",
    "                normal_nll(y, pred_mean, pred_std),\n",
    "                rmse(y, pred_mean),\n",
    "                mae(y, pred_mean),\n",
    "                auc_rmse(y, pred_mean, pred_std),\n",
    "                auc_mae(y, pred_mean, pred_std)))\n",
    "\n",
    "        metrics_mean = np.mean(cv_metrics, axis = 1)\n",
    "        metrics_stderr = scipy.stats.sem(cv_metrics, axis = 1)\n",
    "        \n",
    "        r = Results(\n",
    "            str(datetime.now()),\n",
    "            d, \n",
    "            m.__name__,\n",
    "            X.shape,\n",
    "            *zip(metrics_mean, metrics_stderr)\n",
    "        )\n",
    "        print(r)\n",
    "    return r\n",
    "\n",
    "par_results = Parallel(n_jobs=16)(delayed(eval_dataset_model)(d, X, y) for d, (X, y) in datasets.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15865525393145707"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.norm.cdf(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=datasets['boston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf =  RandomForestRegressor(n_estimators=10)\n",
    "rf.fit(X,y)\n",
    "pred_mean = rf.predict(X)\n",
    "percentile = scipy.stats.norm.cdf(-1) # One Gaussian std\n",
    "err_down = []\n",
    "err_up = []\n",
    "dt_pred = np.vstack([dt.predict(X) for dt in rf.estimators_])\n",
    "err_down = np.percentile(dt_pred, 100*percentile, axis=0)\n",
    "err_up = np.percentile(dt_pred, 100*(1-percentile), axis=0)\n",
    "pred_std = (err_up - err_down)/2\n",
    "\n",
    "for i in range(len(X)):\n",
    "    preds = []\n",
    "    for pred in rf.estimators_:\n",
    "        preds.append(pred.predict(X[i:i+1])[0])\n",
    "    err_down.append(np.percentile(preds, 100*percentile))\n",
    "    err_up.append(np.percentile(preds, 100*(1-percentile)))\n",
    "pred_std = (np.array(err_up) - np.array(err_down))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.5995281 , 21.6       , 34.7       , 33.4       , 33.4       ,\n",
       "       28.7       , 18.9       , 19.31347674, 15.08463566, 16.54278973,\n",
       "       15.        , 18.9       , 19.88557946, 19.9       , 18.2       ,\n",
       "       19.9       , 20.48557946, 17.5       , 20.2       , 18.2       ,\n",
       "       13.1       , 17.5       , 13.84231783, 14.5       , 15.6       ,\n",
       "       13.9       , 16.6       , 14.8       , 18.4       , 19.62695348,\n",
       "       12.7       , 14.5       , 12.91394864, 13.1       , 13.5       ,\n",
       "       18.4995281 , 19.37068701, 20.77115891, 20.28369186, 28.81394864,\n",
       "       33.75579457, 26.6       , 25.08557946, 24.52836919, 20.68510756,\n",
       "       19.3       , 19.47115891, 16.6       , 14.4       , 19.4       ,\n",
       "       19.7       , 20.5       , 25.        , 23.4       , 17.88510756,\n",
       "       33.28557946, 24.7       , 28.41347674, 22.67068701, 19.6       ,\n",
       "       18.7       , 16.        , 22.2       , 23.78557946, 32.54231783,\n",
       "       22.5       , 19.34278973, 21.02742539, 17.4       , 19.68557946,\n",
       "       24.2       , 19.98463566, 22.8       , 23.4       , 23.6995281 ,\n",
       "       20.97115891, 20.        , 20.8       , 20.8       , 20.3       ,\n",
       "       28.        , 23.9       , 24.8       , 22.9       , 22.9       ,\n",
       "       25.74184593, 19.81347674, 22.2       , 23.6       , 28.7       ,\n",
       "       22.6       , 22.        , 22.9       , 24.3995281 , 20.6       ,\n",
       "       26.37115891, 21.4       , 38.7       , 43.8       , 32.22742539,\n",
       "       25.2985843 , 25.2985843 , 18.6       , 19.3       , 19.98557946,\n",
       "       19.0995281 , 18.52742539, 20.22836919, 19.45673837, 18.4       ,\n",
       "       20.1       , 22.8       , 18.8       , 16.88463566, 18.5       ,\n",
       "       18.3       , 20.45626647, 19.2       , 20.4       , 19.3       ,\n",
       "       19.88510756, 20.3       , 18.8       , 17.3       , 16.32742539,\n",
       "       18.58369186, 14.61300484, 14.85626647, 18.        , 14.3       ,\n",
       "       19.2       , 17.9985843 , 19.37115891, 17.82789729, 13.27115891,\n",
       "       18.04278973, 17.4       , 17.1       , 13.3       , 14.55673837,\n",
       "       13.34278973, 12.85626647, 13.4       , 13.4       , 11.8       ,\n",
       "       13.8       , 15.6       , 12.65579457, 14.14231783, 14.02742539,\n",
       "       19.37115891, 16.02742539, 15.3       , 19.4       , 17.        ,\n",
       "       15.6       , 13.1       , 31.01347674, 23.04137403, 22.68557946,\n",
       "       22.32742539, 50.        , 47.71158914, 47.1981124 , 22.12789729,\n",
       "       21.21300484, 50.        , 21.61300484, 21.32836919, 21.62789729,\n",
       "       17.4       , 19.1       , 19.91253294, 23.31394864, 20.12836919,\n",
       "       25.34137403, 19.87068701, 22.1       , 28.52695348, 37.2       ,\n",
       "       36.05579457, 29.6       , 36.92742539, 28.41394864, 26.4       ,\n",
       "       26.4       , 38.7       , 30.11206104, 29.8       , 34.9       ,\n",
       "       34.82600968, 30.5       , 36.4       , 30.75673837, 29.1       ,\n",
       "       50.        , 33.3       , 30.01394864, 32.32742539, 31.87021511,\n",
       "       32.9       , 23.5       , 42.3       , 48.5       , 49.14184593,\n",
       "       22.14231783, 21.08557946, 20.51206104, 18.2976405 , 18.91300484,\n",
       "       20.32695348, 15.81017344, 20.8990562 , 23.98557946, 15.85485077,\n",
       "       21.08557946, 23.3       , 24.22789729, 21.5       , 22.54231783,\n",
       "       24.92648158, 18.44184593, 25.95532267, 23.68557946, 44.8       ,\n",
       "       47.02506588, 37.6       , 29.38510756, 43.02742539, 26.2       ,\n",
       "       20.04278973, 31.64278973, 41.7       , 45.61300484, 25.57068701,\n",
       "       20.27115891, 24.62836919, 31.5       , 23.47115891, 23.3       ,\n",
       "       22.        , 20.1       , 22.2       , 23.7       , 17.32836919,\n",
       "       18.5       , 22.47068701, 19.75626647, 24.38557946, 26.2       ,\n",
       "       24.4       , 23.9995281 , 29.6       , 42.17068701, 21.9       ,\n",
       "       20.9       , 39.65201937, 40.58274806, 36.        , 25.26879941,\n",
       "       33.17068701, 39.03807073, 45.53901453, 30.82836919, 34.95532267,\n",
       "       22.8       , 22.74777227, 37.62600968, 43.5       , 20.7       ,\n",
       "       20.87115891, 25.2       , 24.4       , 35.2       , 29.9985843 ,\n",
       "       31.54231783, 33.14278973, 31.77115891, 24.52836919, 33.32648158,\n",
       "       45.4       , 32.47068701, 46.        , 46.45296317, 32.2       ,\n",
       "       20.74137403, 20.1       , 22.12836919, 22.3       , 24.8       ,\n",
       "       28.5       , 30.46832751, 27.9       , 23.27068701, 21.7       ,\n",
       "       22.81300484, 24.6971686 , 20.3       , 22.5       , 29.        ,\n",
       "       23.1981124 , 22.        , 24.44278973, 32.2990562 , 34.25579457,\n",
       "       26.37115891, 33.4       , 26.36927131, 22.8       , 19.4       ,\n",
       "       16.1       , 22.1       , 19.4       , 21.48557946, 23.8       ,\n",
       "       16.2       , 17.8       , 19.8       , 23.04278973, 21.        ,\n",
       "       23.1       , 23.1       , 20.4       , 18.5       , 25.        ,\n",
       "       23.68463566, 23.        , 19.21394864, 19.12836919, 22.6       ,\n",
       "       19.8       , 17.1       , 19.4       , 22.2       , 20.7       ,\n",
       "       20.6995281 , 19.21394864, 18.5       , 20.6       , 19.        ,\n",
       "       18.7       , 32.7       , 16.5       , 23.27068701, 30.45626647,\n",
       "       17.2       , 17.2       , 23.1       , 24.5       , 25.57021511,\n",
       "       22.2       , 24.1       , 18.6       , 27.67115891, 18.2       ,\n",
       "       20.6       , 12.6       , 21.7       , 21.84184593, 20.44137403,\n",
       "       22.02789729, 19.4995281 , 20.8       , 16.8       , 21.9       ,\n",
       "       22.58510756, 21.27068701, 17.95249127, 24.76879941, 25.32459398,\n",
       "       35.69743213, 22.0985843 , 23.38463566, 10.9       , 11.74043023,\n",
       "       15.        , 10.2       , 13.3       , 10.9       , 10.2       ,\n",
       "       10.4       , 10.2       , 11.3       , 10.67068701,  8.8       ,\n",
       "        7.2       ,  9.52742539,  7.4       ,  7.2       , 11.5       ,\n",
       "       13.27115891, 13.75673837,  9.7       , 13.8       , 10.61394864,\n",
       "       13.1       , 12.5       ,  8.5       ,  5.        ,  6.3       ,\n",
       "        5.6       ,  7.2       ,  8.5       ,  8.3       ,  5.25673837,\n",
       "        5.        , 10.92742539, 21.44184593, 14.85437887, 10.92742539,\n",
       "       15.        , 10.2       , 10.92742539, 10.92742539,  7.        ,\n",
       "        7.2       ,  7.5       ,  9.25579457,  7.55626647,  8.4       ,\n",
       "       13.52789729, 14.2       , 20.02836919, 11.34231783, 11.2995281 ,\n",
       "        8.3       , 10.2       , 10.9       , 11.        ,  9.5       ,\n",
       "       12.5985843 , 14.1       , 16.1       , 13.6995281 , 11.7       ,\n",
       "        8.91206104,  9.6       ,  8.7       ,  7.28557946, 11.38557946,\n",
       "       10.5       , 12.6       , 16.56927131, 15.4       ,  9.98510756,\n",
       "       11.8       , 14.9       , 12.6       , 13.1       , 13.        ,\n",
       "       13.4       , 15.2       , 14.3995281 , 16.42695348, 14.9       ,\n",
       "       13.6995281 , 12.7       , 13.17115891, 14.14278973, 16.81158914,\n",
       "       14.05626647, 16.3995281 , 19.27115891, 19.62789729, 20.54184593,\n",
       "       19.9       , 16.08369186, 15.78180426, 10.2       , 14.40875774,\n",
       "       17.05485077, 19.6       , 17.0995281 , 22.71158914, 13.1       ,\n",
       "       13.3       , 15.21253294, 12.        , 12.6       , 18.5       ,\n",
       "       21.28557946, 23.7       , 25.        , 21.11347674, 20.6       ,\n",
       "       21.2       , 15.78369186, 20.6       , 14.68510756,  7.        ,\n",
       "        8.1       , 13.6       , 19.81394864, 20.65579457, 20.31253294,\n",
       "       21.15485077, 19.7       , 18.3       , 19.24278973, 17.5       ,\n",
       "       16.8       , 22.4       , 20.6       , 23.6       , 22.        ,\n",
       "       11.9       ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.vstack([dt.predict(X) for dt in rf.estimators_]),100*percentile, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('par_results.pkl', 'rb') as f:\n",
    "    pr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\"2018-03-01 20:00:27.904705\", \"boston\", \"LinearRegression\", [506, 13], [2.9621311462524305, 1.4802973661668753e-16], [4.679506300635516, 0.0], [3.272944637996936, 0.0], [4.506588688366446, 2.9605947323337506e-16], [3.9287349258629805, 2.9605947323337506e-16]], [\"2018-03-01 20:00:31.722094\", \"concrete\", \"LinearRegression\", [1030, 8], [3.7562737659149485, 1.4802973661668753e-16], [10.353609808895646, 5.921189464667501e-16], [8.214343706221813, 0.0], [12.67012757796323, 5.921189464667501e-16], [10.959921770889947, 5.921189464667501e-16]], [\"2018-03-01 20:00:30.481193\", \"energy\", \"LinearRegression\", [768, 8], [2.4859556592703806, 1.4802973661668753e-16], [2.906696247412608, 0.0], [2.050870442737076, 1.4802973661668753e-16], [3.4906226888427936, 1.4802973661668753e-16], [2.8544169956933034, 1.4802973661668753e-16]], [\"2018-03-01 20:10:15.380734\", \"kin8nm\", \"LinearRegression\", [8192, 8], [-0.18155005466952676, 9.25185853854297e-18], [0.2017978978983736, 9.25185853854297e-18], [0.16207816062686484, 9.25185853854297e-18], [0.2587637679020988, 1.850371707708594e-17], [0.22269580295435976, 0.0]], [\"2018-03-01 20:23:05.655242\", \"naval\", \"LinearRegression\", [11934, 16], [-3.7255140249761416, 1.4802973661668753e-16], [0.005831665988151014, 2.8912057932946783e-19], [0.004580758965037055, 2.8912057932946783e-19], [0.00709639934936414, 5.782411586589357e-19], [0.006088282415898147, 2.8912057932946783e-19]], [\"2018-03-01 20:15:09.574741\", \"power\", \"LinearRegression\", [9568, 4], [2.9356306985492044, 0.0], [4.557126016749485, 2.9605947323337506e-16], [3.6252158076011822, 1.4802973661668753e-16], [5.60792144234926, 2.9605947323337506e-16], [4.738389953483306, 0.0]], [\"2018-03-01 22:06:50.206270\", \"protein\", \"LinearRegression\", [45730, 9], [3.0643568563172625, 0.0], [5.183177696525771, 0.0], [4.340180923411619, 0.0], [5.490792470558335, 0.0], [5.026014363915223, 0.0]], [\"2018-03-01 20:00:44.639481\", \"wine\", \"LinearRegression\", [1599, 11], [0.9813247506512297, 3.700743415417188e-17], [0.6455750670692045, 0.0], [0.5004899635644876, 3.700743415417188e-17], [0.7933821418725538, 0.0], [0.6699779143188597, 3.700743415417188e-17]], [\"2018-03-01 20:00:27.020027\", \"yacht\", \"LinearRegression\", [308, 6], [3.6001702187390263, 1.4802973661668753e-16], [8.857208839069159, 0.0], [7.160334758510729, 0.0], [8.08381158890587, 5.921189464667501e-16], [7.5869275348082805, 5.921189464667501e-16]], [\"2018-03-01 20:02:13.191882\", \"make_regression\", \"LinearRegression\", [10000, 100], [1.391361461775142, NaN], [0.9727997046002816, NaN], [0.7749067693071197, NaN], [1.1549147047706574, NaN], [1.0082339175632846, NaN]], [\"2018-03-01 20:08:16.214821\", \"make_friedman1\", \"LinearRegression\", [20000, 10], [2.310567313304193, NaN], [2.4390991738677674, NaN], [1.879803516593789, NaN], [3.1755378918250727, NaN], [2.640565686065767, NaN]], [\"2018-03-01 21:01:16.196179\", \"make_friedman2\", \"LinearRegression\", [50000, 4], [6.342420136670596, NaN], [137.48043326674295, NaN], [103.01807954470553, NaN], [161.41520242528304, NaN], [137.14998128342393, NaN]], [\"2018-03-01 23:50:50.612601\", \"make_friedman3\", \"LinearRegression\", [100000, 4], [3.7221766498384974, NaN], [10.006532369061363, NaN], [7.980464058980882, NaN], [11.87936680790716, NaN], [10.37626834916445, NaN]]]'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[shallow_models.RFUncertainty,\n",
       " shallow_models.LinearRegression,\n",
       " shallow_models.BayesianLinearRegression,\n",
       " shallow_models.GBTQuantile,\n",
       " shallow_models.XGBaseline,\n",
       " shallow_models.XGBLogLikelihood]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boston', shallow_models.RFUncertainty),\n",
       " ('boston', shallow_models.LinearRegression),\n",
       " ('boston', shallow_models.BayesianLinearRegression),\n",
       " ('boston', shallow_models.GBTQuantile),\n",
       " ('boston', shallow_models.XGBaseline),\n",
       " ('boston', shallow_models.XGBLogLikelihood),\n",
       " ('concrete', shallow_models.RFUncertainty),\n",
       " ('concrete', shallow_models.LinearRegression),\n",
       " ('concrete', shallow_models.BayesianLinearRegression),\n",
       " ('concrete', shallow_models.GBTQuantile),\n",
       " ('concrete', shallow_models.XGBaseline),\n",
       " ('concrete', shallow_models.XGBLogLikelihood),\n",
       " ('energy', shallow_models.RFUncertainty),\n",
       " ('energy', shallow_models.LinearRegression),\n",
       " ('energy', shallow_models.BayesianLinearRegression),\n",
       " ('energy', shallow_models.GBTQuantile),\n",
       " ('energy', shallow_models.XGBaseline),\n",
       " ('energy', shallow_models.XGBLogLikelihood),\n",
       " ('kin8nm', shallow_models.RFUncertainty),\n",
       " ('kin8nm', shallow_models.LinearRegression),\n",
       " ('kin8nm', shallow_models.BayesianLinearRegression),\n",
       " ('kin8nm', shallow_models.GBTQuantile),\n",
       " ('kin8nm', shallow_models.XGBaseline),\n",
       " ('kin8nm', shallow_models.XGBLogLikelihood),\n",
       " ('naval', shallow_models.RFUncertainty),\n",
       " ('naval', shallow_models.LinearRegression),\n",
       " ('naval', shallow_models.BayesianLinearRegression),\n",
       " ('naval', shallow_models.GBTQuantile),\n",
       " ('naval', shallow_models.XGBaseline),\n",
       " ('naval', shallow_models.XGBLogLikelihood),\n",
       " ('power', shallow_models.RFUncertainty),\n",
       " ('power', shallow_models.LinearRegression),\n",
       " ('power', shallow_models.BayesianLinearRegression),\n",
       " ('power', shallow_models.GBTQuantile),\n",
       " ('power', shallow_models.XGBaseline),\n",
       " ('power', shallow_models.XGBLogLikelihood),\n",
       " ('protein', shallow_models.RFUncertainty),\n",
       " ('protein', shallow_models.LinearRegression),\n",
       " ('protein', shallow_models.BayesianLinearRegression),\n",
       " ('protein', shallow_models.GBTQuantile),\n",
       " ('protein', shallow_models.XGBaseline),\n",
       " ('protein', shallow_models.XGBLogLikelihood),\n",
       " ('wine', shallow_models.RFUncertainty),\n",
       " ('wine', shallow_models.LinearRegression),\n",
       " ('wine', shallow_models.BayesianLinearRegression),\n",
       " ('wine', shallow_models.GBTQuantile),\n",
       " ('wine', shallow_models.XGBaseline),\n",
       " ('wine', shallow_models.XGBLogLikelihood),\n",
       " ('yacht', shallow_models.RFUncertainty),\n",
       " ('yacht', shallow_models.LinearRegression),\n",
       " ('yacht', shallow_models.BayesianLinearRegression),\n",
       " ('yacht', shallow_models.GBTQuantile),\n",
       " ('yacht', shallow_models.XGBaseline),\n",
       " ('yacht', shallow_models.XGBLogLikelihood),\n",
       " ('make_regression', shallow_models.RFUncertainty),\n",
       " ('make_regression', shallow_models.LinearRegression),\n",
       " ('make_regression', shallow_models.BayesianLinearRegression),\n",
       " ('make_regression', shallow_models.GBTQuantile),\n",
       " ('make_regression', shallow_models.XGBaseline),\n",
       " ('make_regression', shallow_models.XGBLogLikelihood),\n",
       " ('make_friedman1', shallow_models.RFUncertainty),\n",
       " ('make_friedman1', shallow_models.LinearRegression),\n",
       " ('make_friedman1', shallow_models.BayesianLinearRegression),\n",
       " ('make_friedman1', shallow_models.GBTQuantile),\n",
       " ('make_friedman1', shallow_models.XGBaseline),\n",
       " ('make_friedman1', shallow_models.XGBLogLikelihood),\n",
       " ('make_friedman2', shallow_models.RFUncertainty),\n",
       " ('make_friedman2', shallow_models.LinearRegression),\n",
       " ('make_friedman2', shallow_models.BayesianLinearRegression),\n",
       " ('make_friedman2', shallow_models.GBTQuantile),\n",
       " ('make_friedman2', shallow_models.XGBaseline),\n",
       " ('make_friedman2', shallow_models.XGBLogLikelihood),\n",
       " ('make_friedman3', shallow_models.RFUncertainty),\n",
       " ('make_friedman3', shallow_models.LinearRegression),\n",
       " ('make_friedman3', shallow_models.BayesianLinearRegression),\n",
       " ('make_friedman3', shallow_models.GBTQuantile),\n",
       " ('make_friedman3', shallow_models.XGBaseline),\n",
       " ('make_friedman3', shallow_models.XGBLogLikelihood)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(d, m) for (d, (X, y)), m in product(datasets.items(), models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
